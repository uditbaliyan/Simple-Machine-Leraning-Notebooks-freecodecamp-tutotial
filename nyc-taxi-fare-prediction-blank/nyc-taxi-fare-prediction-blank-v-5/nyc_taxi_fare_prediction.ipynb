{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymeK3K4P879t"
   },
   "source": [
    "# New York City Taxi Fare Prediction\n",
    "\n",
    "![](https://i.imgur.com/ecwUY8F.png)\n",
    "\n",
    "Dataset Link: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction\n",
    "\n",
    "We'll train a machine learning model to predict the fare for a taxi ride in New York city given information like pickup date & time, pickup location, drop location and no. of passengers. \n",
    "\n",
    "This dataset is taken from a [Kaggle competition](ttps://www.kaggle.com/c/new-york-city-taxi-fare-prediction) organized by Google Cloud. It contains over 55 millions rows of training data. We'll attempt to achieve a respectable score in the competition using just a fraction of the data. Along the way, we'll also look at some practical tips for machine learning. PMost of the ideas & techniques covered in this notebook are derived from other public notebooks & blog posts.\n",
    "\n",
    "To run this notebook, select \"Run\" > \"Run on Colab\" and connect your Google Drive account with Jovian. Make sure to use the GPU runtime if you plan on using a GPU.\n",
    "\n",
    "You can find the completed version of this notebook here: https://jovian.ai/aakashns/nyc-taxi-fare-prediction-filled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovhvtVIlVM0w"
   },
   "source": [
    "\n",
    "> _**TIP #1**: Create an outline for your notebook & for each section before you start coding_\n",
    "\n",
    "\n",
    "\n",
    "Here's an outline of the project:\n",
    "\n",
    "1. Download the dataset\n",
    "2. Explore & analyze the dataset\n",
    "3. Prepare the dataset for ML training\n",
    "4. Train hardcoded & baseline models\n",
    "5. Make predictions & submit to Kaggle\n",
    "6. Peform feature engineering\n",
    "7. Train & evaluate different models\n",
    "8. Tune hyperparameters for the best models\n",
    "9. Train on a GPU with the entire dataset\n",
    "10. Document & publish the project online\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KprVTPb44pV7"
   },
   "source": [
    "## 1. Download the Dataset\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Install required libraries\n",
    "- Download data from Kaggle\n",
    "- View dataset files\n",
    "- Load training set with Pandas\n",
    "- Load test set with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoD0siP-6b5K"
   },
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMPQKKyo6hR_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RwbGaaTLJok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP1AkqGcLKvX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR7X9VVl6h1J"
   },
   "source": [
    "### Download Data from Kaggle\n",
    "\n",
    "We'll use the [opendatasets](https://github.com/JovianML/opendatasets) library to download the dataset. You'll need to upload your [Kaggle API key](https://github.com/JovianML/opendatasets/blob/master/README.md#kaggle-credentials) (a file called `kaggle.json`) to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS0BaBV86j0Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xotpf7sjPUXy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-qbpdozPZXD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2t2w_P_P6n-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRKXBoII6koE"
   },
   "source": [
    "### View Dataset Files\n",
    "\n",
    "Let's look at the size, no. of lines and first few lines of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSeQME-i6nHb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5HqD9eWP_gE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgLfjwBVP_7i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjwJxDjFQZSM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "centXUzKQ9op"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9sEzToXRBbc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZDuA82HRHvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD2m2fpRQUq1"
   },
   "source": [
    "Observations:\n",
    "\n",
    "- This is a supervised learning regression problem\n",
    "- Training data is 5.5 GB in size\n",
    "- Training data has 5.5 million rows\n",
    "- Test set is much smaller (< 10,000 rows)\n",
    "- The training set has 8 columns:\n",
    "    - `key` (a unique identifier)\n",
    "    - `fare_amount` (target column)\n",
    "    - `pickup_datetime`\n",
    "    - `pickup_longitude`\n",
    "    - `pickup_latitude`\n",
    "    - `dropoff_longitude`\n",
    "    - `dropoff_latitude`\n",
    "    - `passenger_count`\n",
    "- The test set has all columns except the target column `fare_amount`.\n",
    "- The submission file should contain the `key` and `fare_amount` for each test sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxF43fGDRw4L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3ECfaXG6opv"
   },
   "source": [
    "### Loading Training Set\n",
    "\n",
    "> _**TIP #2**: When working with large datasets, always start with a sample to experiment & iterate faster._\n",
    "\n",
    "Loading the entire dataset into Pandas is going to be slow, so we can use the following optimizations:\n",
    "\n",
    "- Ignore the `key` column\n",
    "- Parse pickup datetime while loading data \n",
    "- Specify data types for other columns\n",
    "   - `float32` for geo coordinates\n",
    "   - `float32` for fare amount\n",
    "   - `uint8` for passenger count\n",
    "- Work with a 1% sample of the data (~500k rows)\n",
    "\n",
    "We can apply these optimizations while using [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvqQSC5NTK3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eismtxh2-h8o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53-fOkat6qoX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO56LkL8XseO"
   },
   "source": [
    "> _**TIP #3**: Fix the seeds for random number generators so that you get the same results every time you run your notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7jXNVGBUwhQ"
   },
   "source": [
    "**Exercise**: Try loading 3%, 10%, 30% and 100% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ye0DzTlkTSV7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riKehMfZ6vbT"
   },
   "source": [
    "### Load Test Set\n",
    "\n",
    "For the test set, we'll simply provide the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOO33o4o6xDS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oqXKAsbTYPl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LwhALNRTn0z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9CYWu1c6yD9"
   },
   "source": [
    "## 2. Explore the Dataset\n",
    "\n",
    "- Basic info about training set\n",
    "- Basic info about test set\n",
    "- Exploratory data analysis & visualization\n",
    "- Ask & answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK044Ke76_QB"
   },
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThJJwhCR7Gzb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrcLO35KTsWi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5jzYKMNTuQc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WIzKrOwTzGv"
   },
   "source": [
    "Observations about training data:\n",
    "\n",
    "- 550k+ rows, as expected\n",
    "- No missing data (in the sample)\n",
    "- `fare_amount` ranges from \\$-52.0 to \\$499.0 \n",
    "- `passenger_count` ranges from 0 to 208 \n",
    "- There seem to be some errors in the latitude & longitude values\n",
    "- Dates range from 1st Jan 2009 to 30th June 2015\n",
    "- The dataset takes up ~19 MB of space in the RAM\n",
    "\n",
    "We may need to deal with outliers and data entry errors before we train our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtRcylCW7Hvu"
   },
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zK-AtxR_7I6X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKA33FctWGEe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRudxeE2Wfhm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQRCB4HiWLYb"
   },
   "source": [
    "Some observations about the test set:\n",
    "\n",
    "- 9914 rows of data\n",
    "- No missing values\n",
    "- No obvious data entry errors\n",
    "- 1 to 6 passengers (we can limit training data to this range)\n",
    "- Latitudes lie between 40 and 42\n",
    "- Longitudes lie between -75 and -72\n",
    "- Pickup dates range from Jan 1st 2009 to Jun  30th 2015 (same as training set)\n",
    "\n",
    "We can use the ranges of the test set to drop outliers/invalid data from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f1FsdiWWqPX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckZBVEMt7PMa"
   },
   "source": [
    "### Exploratory Data Analysis and Visualization\n",
    "\n",
    "**Exercise**: Create graphs (histograms, line charts, bar charts, scatter plots, box plots, geo maps etc.) to study the distrubtion of values in each column, and the relationship of each input column to the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdYzucgt7RkC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoQzsx04W-oC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-NiN3shYpbj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpkjXgOr7Yaq"
   },
   "source": [
    "### Ask & Answer Questions\n",
    "\n",
    "**Exercise**: Ask & answer questions about the dataset: \n",
    "\n",
    "1. What is the busiest day of the week?\n",
    "2. What is the busiest time of the day?\n",
    "3. In which month are fares the highest?\n",
    "4. Which pickup locations have the highest fares?\n",
    "5. Which drop locations have the highest fares?\n",
    "6. What is the average ride distance?\n",
    "7. ???\n",
    "\n",
    "Performing EDA on your dataset and asking questions will help you develop a deeper understand of the data and give you ideas for feature engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE0-j7ibYtdt"
   },
   "source": [
    "\n",
    "Resources for exploratory analysis & visualization:\n",
    "\n",
    "- EDA project from scratch: https://www.youtube.com/watch?v=kLDTbavcmd0\n",
    "- Data Analysis with Python: https://zerotopandas.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBoP2YdZZOcL"
   },
   "source": [
    "> _**TIP #4**: Take an iterative approach to building ML models: do some EDA, do some feature engineering, train a model, then repeat to improve your model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qfgCMC77SEQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NassE2WYpC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsF4sPdDYpur"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzdkh1wkYqNj"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo0ue49U7eu4"
   },
   "source": [
    "## 3. Prepare Dataset for Training\n",
    "\n",
    "- Split Training & Validation Set\n",
    "- Fill/Remove Missing Values\n",
    "- Extract Inputs & Outputs\n",
    "   - Training\n",
    "   - Validation\n",
    "   - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mswEXeiu7mrA"
   },
   "source": [
    "### Split Training & Validation Set\n",
    "\n",
    "We'll set aside 20% of the training data as the validation set, to evaluate the models we train on previously unseen data. \n",
    "\n",
    "Since the test set and training set have the same date ranges, we can pick a random 20% fraction.\n",
    "\n",
    "> _**TIP #5**: Your validation set should be as similar to the test set or real-world data as possible i.e. the evaluation metric score of a model on validation & test sets should be very close, otherwise you're shooting in the dark._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-A1hKczB7U0I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "223dkJPcZ5wM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fci2Mg9mZ6Dj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RREUhZFx7k37"
   },
   "source": [
    "### Fill/Remove Missing Values\n",
    "\n",
    "There are no missing values in our sample, but if there were, we could simply drop the rows with missing values instead of trying to fill them (since we have a lot of training data)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62tQ1Mkj-B1U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8aL-x9C-Gc5"
   },
   "source": [
    "### Extract Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EznRfztapJd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20_-9TgMapjR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CAarE7UapzF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b-bhEhS-Mz6"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zTNkuqe-H3O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsdfMMSybTsQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTNMLeEMbbT3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMnOoZ4Gbc3v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj49BUY_-InI"
   },
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR-5yVjY-PZV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bL75iGCkbe3t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzYDUti4blBd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPwn69GPbmsk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxUKnWZG-SEP"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwMU1U-S04"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz0jK2pZbpiT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OG4p3TcKbpQK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D69gMpoc-T3x"
   },
   "source": [
    "## 4. Train Hardcoded & Baseline Models\n",
    "\n",
    "> _**TIP #6**: Always create a simple hardcoded or baseline model to establish the minimum score any proper ML model should beat._\n",
    "\n",
    "- Hardcoded model: always predict average fare\n",
    "- Baseline model: Linear regression \n",
    "\n",
    "For evaluation the dataset uses RMSE error: \n",
    "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HojOJqvh-8I2"
   },
   "source": [
    "### Train & Evaluate Hardcoded Model\n",
    "\n",
    "Let's create a simple model that always predicts the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egLCJe0TdrGF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi3N8Kkh-_SZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br8KFvGQdeWW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnR-_BSzdeqO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyJOWf0-dkbr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Mp2LEKHdktj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkbSKOZqdm0z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvJkxaImdnP1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHoIUSyXdupG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kedz-UOFd4kM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJLGGq3Rdu6U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q6zRkNyeLSm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O46X0AFWdyYx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXVmrtzRd7lb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52_3bDeJeOLl"
   },
   "source": [
    "Our dumb hard-coded model is off by \\$9.899 on average, which is pretty bad considering the average fare is \\$11.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xd9QsynHd7yb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwWoP6if-_uA"
   },
   "source": [
    "### Train & Evaluate Baseline Model\n",
    "\n",
    "We'll train a linear regression model as our baseline, which tries to express the target as a weighted sum of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2ivNSaf_Bh3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSsDURPWecmP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9vkP2Wbec3Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFYfI2fledIo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyeI6iZmemFM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gv3omU8emm-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6SIpnucem5D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3y9WJfSe6Um"
   },
   "source": [
    "The linear regression model is off by $9.898, which isn't much better than simply predicting the average. \n",
    "\n",
    "This is mainly because the training data (geocoordinates) is not in a format that's useful for the model, and we're not using one of the most important columns: pickup date & time.\n",
    "\n",
    "However, now we have a baseline that our other models should ideally beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqVt3xmsgJwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c1nCUvn_B_o"
   },
   "source": [
    "## 5. Make Predictions and Submit to Kaggle\n",
    "\n",
    "> _**TIP #7**: When working on a Kaggle competition, submit early and submit often (ideally daily). The best way to improve your models is to try & beat your previous score._\n",
    "\n",
    "- Make predictions for test set\n",
    "- Generate submissions CSV\n",
    "- Submit to Kaggle\n",
    "- Record in experiment tracking sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtRdQgUV_Fh4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaFg2Pc2gaOU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JatqolD1gado"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UM0edzAgatI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWqY-qJ4bnlf"
   },
   "source": [
    "> _**TIP #8**: Create reusable functions for common tasks. They'll help you iterate faster and free up your mind to think about new ideas._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1rSS5Ctgjs_"
   },
   "outputs": [],
   "source": [
    "def predict_and_submit(model, fname):\n",
    "    test_preds = model.predict(test_inputs)\n",
    "    sub_df = pd.read_csv(data_dir+'/sample_submission.csv')\n",
    "    sub_df['fare_amount'] = test_preds\n",
    "    sub_df.to_csv(fname, index=None)\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo7t2RcYgkCL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA3RD2_BjHo7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IBHaekXgkSD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZpNqiYieqJs"
   },
   "source": [
    "> _**TIP #9**: Track your ideas & experiments systematically to avoid become overwhelmed with dozens of models. Use this template: https://bit.ly/mltrackingsheet_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEbYT2mG_HgG"
   },
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "> _**TIP #10**: Take an iterative approach to feature engineering. Add some features, train a model, evaluate it, keep the features if they help, otherwise drop them, then repeat._\n",
    "\n",
    "- Extract parts of date\n",
    "- Remove outliers & invalid data\n",
    "- Add distance between pickup & drop\n",
    "- Add distance from landmarks\n",
    "\n",
    "Exercise: We're going to apply all of the above together, but you should observer the effect of adding each feature individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUB8lxy_sg6"
   },
   "source": [
    "### Extract Parts of Date\n",
    "\n",
    "- Year\n",
    "- Month\n",
    "- Day\n",
    "- Weekday\n",
    "- Hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2CivTql_2Fu"
   },
   "outputs": [],
   "source": [
    "def add_dateparts(df, col):\n",
    "    df[col + '_year'] = df[col].dt.year\n",
    "    df[col + '_month'] = df[col].dt.month\n",
    "    df[col + '_day'] = df[col].dt.day\n",
    "    df[col + '_weekday'] = df[col].dt.weekday\n",
    "    df[col + '_hour'] = df[col].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOx5_kxOjZB5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDXVCaADjZT-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykp-Xdy-jY7A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzvyUWROkhfG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr1KUnq8khXQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqmAKOdfASXX"
   },
   "source": [
    "### Add Distance Between Pickup and Drop\n",
    "\n",
    "We can use the haversine distance: \n",
    "- https://en.wikipedia.org/wiki/Haversine_formula\n",
    "- https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmFyo4MRCB67"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahz4-U7GzoEM"
   },
   "outputs": [],
   "source": [
    "def add_trip_distance(df):\n",
    "    df['trip_distance'] = haversine_np(df['pickup_longitude'], df['pickup_latitude'], df['dropoff_longitude'], df['dropoff_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvqOy7V409FF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojOOKh7i5rhC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gqd69jAX5tXY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMRIiNqw08uZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFpeLO4MCP4J"
   },
   "source": [
    "### Add Distance From Popular Landmarks\n",
    "\n",
    "> _**TIP #11**: Creative feature engineering (generally involving human insight or external data) is a lot more effective than excessive hyperparameter tuning. Just one or two good feature improve the model's performance drastically._\n",
    "\n",
    "- JFK Airport\n",
    "- LGA Airport\n",
    "- EWR Airport\n",
    "- Times Square\n",
    "- Met Meuseum\n",
    "- World Trade Center\n",
    "\n",
    "We'll add the distance from drop location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_hrTiYRAO5D"
   },
   "outputs": [],
   "source": [
    "jfk_lonlat = -73.7781, 40.6413\n",
    "lga_lonlat = -73.8740, 40.7769\n",
    "ewr_lonlat = -74.1745, 40.6895\n",
    "met_lonlat = -73.9632, 40.7794\n",
    "wtc_lonlat = -74.0099, 40.7126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLTcCYNKCS04"
   },
   "outputs": [],
   "source": [
    "def add_landmark_dropoff_distance(df, landmark_name, landmark_lonlat):\n",
    "    lon, lat = landmark_lonlat\n",
    "    df[landmark_name + '_drop_distance'] = haversine_np(lon, lat, df['dropoff_longitude'], df['dropoff_latitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuKlVwkzBNRl"
   },
   "outputs": [],
   "source": [
    "def add_landmarks(df):\n",
    "  landmarks = [('jfk', jfk_lonlat), ('lga', lga_lonlat), ('ewr', ewr_lonlat), ('met', met_lonlat), ('wtc', wtc_lonlat)]\n",
    "  for name, lonlat in landmarks:\n",
    "    add_landmark_dropoff_distance(a_df, name, lonlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vspm4UZlBx0S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh54p18fcbAU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USE10_QUcbY3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm99KRT__3GS"
   },
   "source": [
    "### Remove Outliers and Invalid Data\n",
    "\n",
    "There seems to be some invalid data in each of the following columns:\n",
    "\n",
    "- Fare amount\n",
    "- Passenger count\n",
    "- Pickup latitude & longitude\n",
    "- Drop latitude & longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu1iN719AQX9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCw4gevKcedV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0Z33hGclw04"
   },
   "source": [
    "We'll use the following ranges:\n",
    "\n",
    "- `fare_amount`: \\$1 to \\$500\n",
    "- `longitudes`: -75 to -72\n",
    "- `latitudes`: 40 to 42\n",
    "- `passenger_count`: 1 to 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HXy4CHsk_sI"
   },
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    return df[(df['fare_amount'] >= 1.) & \n",
    "              (df['fare_amount'] <= 500.) &\n",
    "              (df['pickup_longitude'] >= -75) & \n",
    "              (df['pickup_longitude'] <= -72) & \n",
    "              (df['dropoff_longitude'] >= -75) & \n",
    "              (df['dropoff_longitude'] <= -72) & \n",
    "              (df['pickup_latitude'] >= 40) & \n",
    "              (df['pickup_latitude'] <= 42) & \n",
    "              (df['dropoff_latitude'] >=40) & \n",
    "              (df['dropoff_latitude'] <= 42) & \n",
    "              (df['passenger_count'] >= 1) & \n",
    "              (df['passenger_count'] <= 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQPGJQmik_pR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqndbWx-k_jG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIQjeVA6yACo"
   },
   "source": [
    "### Scaling and One-Hot Encoding\n",
    "\n",
    "**Exercise**: Try scaling numeric columns to the `(0,1)` range and encoding categorical columns using a one-hot encoder.\n",
    "\n",
    "We won't do this because we'll be training tree-based models which are generally able to do a good job even without the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VZfxghqD7Ow"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pgx8tBEyD7im"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFbB6PkkD9X2"
   },
   "source": [
    "### Save Intermediate DataFrames\n",
    "\n",
    "> _**TIP #12**: Save preprocessed & prepared data files to save time & experiment faster. You may also want to create differnt notebooks for EDA, feature engineering and model training._\n",
    "\n",
    "Let's save the processed datasets in the Apache Parquet format, so that we can load them back easily to resume our work from this point.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w26KhYmIEBO0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u7e8FxdEBsR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjAvvW6_EmVI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaILwZZNyeob"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SxgQec8E8iF"
   },
   "source": [
    "## 7. Train & Evaluate Different Models\n",
    "\n",
    "We'll train each of the following & submit predictions to Kaggle:\n",
    "\n",
    "- Linear Regression\n",
    "- Random Forests\n",
    "- Gradient Boosting\n",
    "\n",
    "Exercise: Train Ridge, SVM, KNN, Decision Tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP_jiS_ZFDL2"
   },
   "source": [
    "### Split Inputs & Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-nmx270E-7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vy778UxeE-eG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgeRhiSdE-Rr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8Js99j5F450"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIMlsS7pF4qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m47bx3LEF9Iu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-gkmg0BFG4b"
   },
   "source": [
    "Let's define a helper function to evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSnSkTrXExU1"
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    train_preds = model.predict(train_inputs)\n",
    "    train_rmse = mean_squared_error(train_targets, train_preds, squared=False)\n",
    "    val_preds = model.predict(val_inputs)\n",
    "    val_rmse = mean_squared_error(val_targets, val_preds, squared=False)\n",
    "    return train_rmse, val_rmse, train_preds, val_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOtwHcOzFRn4"
   },
   "source": [
    "### Ridge Regression\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHGpiRjbGjFf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nf2a_i3FTV7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_Gk8A4qGtea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nHsAUg5GtT0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrTd7DSuG4og"
   },
   "source": [
    "Our model was able to get to an RMSE of $5.2, much better than our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leUTkRhVG4T2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asLsXKZxHceo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Be_1ibE3G4Fg"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwLUw-xXFdRj"
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynZuqnImHuR3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYWVBE0bHuOg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEC8Ll3LHuLN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUnb5t8dFe7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTXYvMefIaPM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nvcXsLnIozx"
   },
   "source": [
    "\n",
    "This puts us at position ~570 out of 1483 i.e. top 40%, which is already a really good score. \n",
    "\n",
    "Remember that we're only using 1% of the data, and we haven't done much hyperparameter tuning yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpM6yKErIoS0"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tK7hXI8IFgZ5"
   },
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "See https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpPz5PvBFjxb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWka7h5_ycx2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0RqiicaInkM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htjm_0kpIn1u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmDlr-AbLIFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LqXWIBCLxUR"
   },
   "source": [
    "\n",
    "\n",
    "This submission isn't as good as the random forest, but there's scope for improvement with Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvZ2zv0XLw8r"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlXJfN46FvnD"
   },
   "source": [
    "## 8. Tune Hyperparmeters\n",
    "\n",
    "https://towardsdatascience.com/mastering-xgboost-2eb6bce6bc76\n",
    "\n",
    "\n",
    "We'll train parameters for the XGBoost model. Here’s a strategy for tuning hyperparameters:\n",
    "\n",
    "- Tune the most important/impactful hyperparameter first e.g. n_estimators\n",
    "\n",
    "- With the best value of the first hyperparameter, tune the next most impactful hyperparameter\n",
    "\n",
    "- And so on, keep training the next most impactful parameters with the best values for previous parameters...\n",
    "\n",
    "- Then, go back to the top and further tune each parameter again for further marginal gains\n",
    "\n",
    "- Hyperparameter tuning is more art than science, unfortunately. Try to get a feel for how the parameters interact with each other based on your understanding of the parameter…\n",
    "\n",
    "Let's define a helper function for trying different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdOzypc7MN-x"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_params(ModelClass, **params):\n",
    "    \"\"\"Trains a model with the given parameters and returns training & validation RMSE\"\"\"\n",
    "    model = ModelClass(**params).fit(train_inputs, train_targets)\n",
    "    train_rmse = mean_squared_error(model.predict(train_inputs), train_targets, squared=False)\n",
    "    val_rmse = mean_squared_error(model.predict(val_inputs), val_targets, squared=False)\n",
    "    return train_rmse, val_rmse\n",
    "\n",
    "def test_param_and_plot(ModelClass, param_name, param_values, **other_params):\n",
    "    \"\"\"Trains multiple models by varying the value of param_name according to param_values\"\"\"\n",
    "    train_errors, val_errors = [], [] \n",
    "    for value in param_values:\n",
    "        params = dict(other_params)\n",
    "        params[param_name] = value\n",
    "        train_rmse, val_rmse = test_params(ModelClass, **params)\n",
    "        train_errors.append(train_rmse)\n",
    "        val_errors.append(val_rmse)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Overfitting curve: ' + param_name)\n",
    "    plt.plot(param_values, train_errors, 'b-o')\n",
    "    plt.plot(param_values, val_errors, 'r-o')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGX0-Lm4OGhx"
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'reg:squarederror'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhEXG369HLLA"
   },
   "source": [
    "### No. of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iz2QgfIqHOvx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_Qj968PPSMZ"
   },
   "source": [
    "Seems like 500 estimators has the lowest validation loss. However, it also takes a long time. Let's stick with 250 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWDujeerPSo5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV3jbIapHIpp"
   },
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeF82yZTHKuq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG3dBJkYQjfv"
   },
   "source": [
    "Looks like a max depth of 5 is ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwF0TM08QkIY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVEN-IY4HGgJ"
   },
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ok26BhAlFyK_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y414md7SYMo"
   },
   "source": [
    "Seems like the best learning rate is 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvJDejVNSYet"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izR7k6LXHdCQ"
   },
   "source": [
    "### Other Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxVopdbbOEcq"
   },
   "source": [
    "Similarly we can experiment with other parameters. \n",
    "\n",
    "Here's a set of parameters that works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5cxbbzqNwfk"
   },
   "outputs": [],
   "source": [
    "xgb_model_final = XGBRegressor(objective='reg:squarederror', \n",
    "                               n_jobs=-1, \n",
    "                               random_state=42,\n",
    "                               n_estimators=500, \n",
    "                               max_depth=5, \n",
    "                               learning_rate=0.1, \n",
    "                               subsample=0.8, \n",
    "                               colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0CNujFUSTpz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMskj9MiHmBT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTMSYvczTOMx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KSk5Hr9Thsj"
   },
   "source": [
    "\n",
    "\n",
    "This puts us at the ~460th position out of 1483 i.e. top 30%. This is pretty amazing considering:\n",
    "\n",
    "- We are using just 1% of the training data\n",
    "- We are only using a single model (most top submissions use ensembles)\n",
    "- Our best model takes just 10 minutes to train (as oppposed to hours/days)\n",
    "- We haven't fully optimized the hyperparameters yet\n",
    "\n",
    "Let's save the weights of this model. Follow this guide: https://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5hZNwxIThdN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QU_QcincWhsA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWE4S1MBWiRI"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg52gR1hIH9E"
   },
   "source": [
    "**Exercises**: \n",
    "\n",
    "1. Tune hyperparameters for Linear Regression & random forests.\n",
    "2. Repeat with 3%, 10%, 30% and 100% of the training set. How much reduction in error does 100x more data produce?\n",
    "3. Ensemble (average) the results from multiple models and observe if they're better than individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrlKunTpU5CB"
   },
   "source": [
    "### Save Model Weights to Google Drive (Optional)\n",
    "\n",
    "We can save all the output files we've created to Google Drive, so that we can reuse them later if required.\n",
    "\n",
    "Follow these guides: \n",
    "- https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "- https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IFHEsklVCKb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6T1lsTeVCdT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMA4a4a0WAkE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEgYBB7SHpIe"
   },
   "source": [
    "## 9. Train on GPU with entire dataset (Optional)\n",
    "\n",
    "Steps:\n",
    "- Install `dask`, `cudf` and `cuml`\n",
    "- Load the dataset to GPU\n",
    "- Create training and validation set\n",
    "- Perform feature engineering\n",
    "- Train XGBoost `cuml` model\n",
    "- Make predictions & submit\n",
    "\n",
    "Follow these guides and fill out the empty cells below:\n",
    "- https://towardsdatascience.com/nyc-taxi-fare-prediction-605159aa9c24\n",
    "- https://jovian.ai/allenkong221/nyc-taxi-fare-rapids-dask-gpu/v/1?utm_source=embed#C10\n",
    "- https://developer.nvidia.com/blog/accelerating-xgboost-on-gpu-clusters-with-dask/\n",
    "- https://rapids.ai/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl9xnk85Hsbq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8XY3M4LH8xB"
   },
   "source": [
    "### Install `dask`, `cudf` and `cuml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tK78LbdIf1m"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T0mffaGIgTg"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbcghTdkIhaF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbAgCLouIh0q"
   },
   "source": [
    "### Create training & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_2j3bfdIjjE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD2FJpDRIkJo"
   },
   "source": [
    "### Perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU7eGJ79Ilrs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Fauiz4JNQa"
   },
   "source": [
    "### Train XGBoost model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JolgKXPYJO3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUFO3Id3JPbk"
   },
   "source": [
    "### Make Predictions & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sitr9vvNJROO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2Y3EUAIJSai"
   },
   "source": [
    "## 10. Document & Publish Your Work\n",
    "\n",
    "> _**TIP #13**: Always document & publish your projects online. They help improve your understanding, showcase your skills & often lead to inbound job opportunities._\n",
    "\n",
    "- Add explanations using Markdown\n",
    "- Clean up the code & create functions\n",
    "- Publish notebook to Jovian\n",
    "- Write a blog post and embed\n",
    "\n",
    "Follow this guide: https://www.youtube.com/watch?v=NK6UYg3-Bxs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AA1qCyqVLew"
   },
   "source": [
    "## References\n",
    "\n",
    "* Dataset: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview\n",
    "* Missing semester (Shell scripting): https://missing.csail.mit.edu/\n",
    "* Opendatsets library: https://github.com/JovianML/opendatasets \n",
    "* EDA project from scratch: https://www.youtube.com/watch?v=kLDTbavcmd0\n",
    "* GeoPy: https://geopy.readthedocs.io/en/stable/#module-geopy.distance \n",
    "* Blog post by Allen Kong: https://towardsdatascience.com/nyc-taxi-fare-prediction-605159aa9c24 \n",
    "* Machine Learning with Python: Zero to GBMs - https://zerotogbms.com \n",
    "* Experiment tracking spreadsheet: https://bit.ly/mltrackingsheet \n",
    "* Pandas datetime components: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components \n",
    "* Haversine distance: https://en.wikipedia.org/wiki/Haversine_formula \n",
    "* Haversine distance with Numpy: https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas \n",
    "* RAPIDS (parent project for cudf and cuml): https://rapids.ai/\n",
    "* Data Science blog post from scratch: https://www.youtube.com/watch?v=NK6UYg3-Bxs \n",
    "* Examples of Machine Learning Projects:\n",
    "    * Walmart Store Sales: https://jovian.ai/anushree-k/final-walmart-simple-rf-gbm\n",
    "    * Used Car Price Prediction: https://jovian.ai/kara-mounir/used-cars-prices \n",
    "    * Lithology Prediction: https://jovian.ai/ramysaleem/ml-project-machine-predicting-lithologies\n",
    "    * Ad Demand Prediction: https://jovian.ai/deepa-sarojam/online-ad-demand-prediction-ml-prj \n",
    "    * Financial distress prediction: https://jovian.ai/sm-wilson/ml-project-financial-distress-prediction\n",
    "    * Credit scoring: https://jovian.ai/shenghongzhong/credit-scores-algorithms-ml-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "executionInfo": {
     "elapsed": 14991,
     "status": "ok",
     "timestamp": 1635602667676,
     "user": {
      "displayName": "Aakash N S",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEhN-SUD4acXtkX_d8m7mxWmrngRSQYIe55adBOg=s64",
      "userId": "05836266386358934739"
     },
     "user_tz": -330
    },
    "id": "lUvguNEdgTbM",
    "outputId": "75e5503e-48d9-42c0-de82-6f16c2498814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
      "API KEY: ··········\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "Committed successfully! https://jovian.ai/aakashns/nyc-taxi-fare-prediction-blank\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/aakashns/nyc-taxi-fare-prediction-blank'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drSwCN9HgUdW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "nyc_taxi_fare_prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}